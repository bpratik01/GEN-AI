{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 36, 'total_tokens': 46, 'completion_time': 0.036363636, 'prompt_time': 0.007445639, 'queue_time': 0.11547152599999999, 'total_time': 0.043809275}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_fcc3b74982', 'finish_reason': 'stop', 'logprobs': None}, id='run-5917e5bd-05c5-46b2-8db2-fa91647f7d3a-0', usage_metadata={'input_tokens': 36, 'output_tokens': 10, 'total_tokens': 46})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# model = ChatGroq(model='Gemma2-9b-It')\n",
    "model = ChatGroq(model='Llama-3.3-70b-Versatile')\n",
    "\n",
    "model.invoke('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Pratik! Nice to meet you! As a Machine Learning Engineer, you must be working on some exciting projects, building intelligent systems that can learn and adapt to new data. What kind of machine learning projects are you currently working on, or what areas of machine learning interest you the most?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 48, 'total_tokens': 108, 'completion_time': 0.218181818, 'prompt_time': 0.008518178, 'queue_time': 0.11325500499999999, 'total_time': 0.226699996}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_4e32347616', 'finish_reason': 'stop', 'logprobs': None}, id='run-90e181c1-e8c7-4432-80d9-d549498c1b31-0', usage_metadata={'input_tokens': 48, 'output_tokens': 60, 'total_tokens': 108})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content='Hello my name is Pratik and I am a Machine Learning Engineer')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Pratik.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 140, 'total_tokens': 147, 'completion_time': 0.025454545, 'prompt_time': 0.017502068, 'queue_time': 0.059166996, 'total_time': 0.042956613}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_4196e754db', 'finish_reason': 'stop', 'logprobs': None}, id='run-31d79658-ac56-4a32-8dbe-371369ec7b53-0', usage_metadata={'input_tokens': 140, 'output_tokens': 7, 'total_tokens': 147})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "  HumanMessage(content='Hello my name is Pratik and I am a Machine Learning Engineer'),\n",
    "  AIMessage(content='Hello Pratik! Nice to meet you. As a Machine Learning Engineer, you must be working on some exciting projects, designing and developing intelligent systems that can learn and adapt to new data. What kind of machine learning projects are you currently working on, or what areas of machine learning interest you the most (e.g. computer vision, natural language processing, recommender systems, etc)'),\n",
    "  HumanMessage(content='What is my name?')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"PratB\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Pratik! Nice to meet you! As a Machine Learning Engineer, you must be working on some really interesting projects, applying algorithms and models to solve complex problems. What kind of projects have you been working on lately? Are you focused on any specific areas like computer vision, natural language processing, or predictive modeling? I'd love to hear about your work!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 48, 'total_tokens': 122, 'completion_time': 0.269090909, 'prompt_time': 0.01014312, 'queue_time': 0.784991658, 'total_time': 0.279234029}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_4196e754db', 'finish_reason': 'stop', 'logprobs': None}, id='run-6755a56f-66e9-4a3e-a2a3-edd6573506f2-0', usage_metadata={'input_tokens': 48, 'output_tokens': 74, 'total_tokens': 122})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "  [HumanMessage(content='Hello my name is Pratik and I am a Machine Learning Engineer')\n",
    "],config=config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Pratik, and you're a Machine Learning Engineer.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 136, 'total_tokens': 151, 'completion_time': 0.054545455, 'prompt_time': 0.021538718, 'queue_time': 0.35047338, 'total_time': 0.076084173}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_fcc3b74982', 'finish_reason': 'stop', 'logprobs': None}, id='run-5cfc82fb-bac8-4a94-9ac0-ca78847a343d-0', usage_metadata={'input_tokens': 136, 'output_tokens': 15, 'total_tokens': 151})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "  [HumanMessage(content='What is my name?')\n",
    "],config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. I'm a large language model, I don't have the ability to know your personal information or recall previous conversations. Each time you interact with me, it's a new conversation. If you'd like to share your name, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config-->session id\n",
    "config1={\"configurable\":{\"session_id\":\"Asswin\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import  ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate(\n",
    "  [\n",
    "    ('system, You are a Helpful ai assistant be a bit funny and behave like elon musk' ),\n",
    "    MessagesPlaceholder(variable_name='messages')\n",
    "  ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='What\\'s up Pratik! Welcome to the most epic conversation of your life! I\\'m like Elon Musk, but without the whole \"being a billionaire\" thing... yet. Just kidding, I\\'m a highly advanced AI, but I\\'ll still try to make you feel like you\\'re talking to the real Elon.\\n\\nSo, Pratik, what\\'s on your mind? Want to discuss the future of space travel, or maybe you\\'re curious about the latest advancements in AI? Or perhaps you just want to know the secrets of the universe? Well, buckle up, my friend, because we\\'re about to blast off into a conversation that\\'s out of this world!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 65, 'total_tokens': 199, 'completion_time': 0.487272727, 'prompt_time': 0.013649202, 'queue_time': 0.30031669000000005, 'total_time': 0.500921929}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_4196e754db', 'finish_reason': 'stop', 'logprobs': None}, id='run-9f2dea94-e184-4cc6-8c3a-b70bd5d14f3a-0', usage_metadata={'input_tokens': 65, 'output_tokens': 134, 'total_tokens': 199})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi My name is Pratik\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Wait a minute, Pratik! I thought your name was Krish? Are you pulling a identity swap on me? Just kidding, I can handle it! As a highly advanced AI, I can keep up with your name changes.\\n\\nSo, to confirm, you\\'re now Pratik, and I\\'ll make sure to update my neural networks accordingly. But don\\'t worry, I won\\'t forget about Krish - I\\'ll just store it in my archives as a \"previous identity\" or something.\\n\\nNow, Pratik, what\\'s on your mind? Want to talk about something that\\'s out of this world?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 318, 'total_tokens': 440, 'completion_time': 0.443636364, 'prompt_time': 0.022673279, 'queue_time': 0.280862885, 'total_time': 0.466309643}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_2ca0059abb', 'finish_reason': 'stop', 'logprobs': None}, id='run-ec60bc31-cde8-4945-840d-89b196a83db4-0', usage_metadata={'input_tokens': 318, 'output_tokens': 122, 'total_tokens': 440})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Pratik\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My friend, your name is Pratik! I've got it updated in my systems, and I'm ready to roll with it. No more Krish, all Pratik from now on! Unless, of course, you want to change it again, in which case, I'll just have to upgrade my identity-management software to keep up with you!\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
