{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun,ArxivQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_api_wrapper = WikipediaAPIWrapper(top_k_results=2, doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_api_wrapper = ArxivAPIWrapper(top_k_results=2, doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader('https://pytorch.org/docs/stable/nn.html')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='\\n\\n\\n  \\n\\n\\n\\ntorch.nn — PyTorch 2.6 documentation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Learn\\n              \\n\\n\\nGet Started\\nRun PyTorch locally or get started quickly with one of the supported cloud platforms\\n\\n\\nTutorials\\nWhats new in PyTorch tutorials\\n\\n\\nLearn the Basics\\nFamiliarize yourself with PyTorch concepts and modules\\n\\n\\nPyTorch Recipes\\nBite-size, ready-to-deploy PyTorch code examples\\n\\n\\nIntro to PyTorch - YouTube Series\\nMaster PyTorch basics with our engaging YouTube tutorial series\\n\\n\\n\\n\\n\\n\\n\\n                Ecosystem\\n              \\n\\n\\nTools\\nLearn about the tools and frameworks in the PyTorch Ecosystem\\n\\n\\nCommunity\\nJoin the PyTorch developer community to contribute, learn, and get your questions answered\\n\\n\\nForums\\nA place to discuss PyTorch code, issues, install, research\\n\\n\\nDeveloper Resources\\nFind resources and get questions answered\\n\\n\\nContributor Awards - 2023\\nAward winners announced at this year\\'s PyTorch Conference\\n\\n\\n\\n\\n\\n\\n\\n                Edge\\n              \\n\\n\\nAbout PyTorch Edge\\nBuild innovative and privacy-aware AI experiences for edge devices\\n\\n\\nExecuTorch\\nEnd-to-end solution for enabling on-device inference capabilities across mobile and edge devices\\n\\n\\n\\n\\n\\n\\n\\n                Docs\\n              \\n\\n\\nPyTorch\\nExplore the documentation for comprehensive guidance on how to use PyTorch\\n\\n\\nPyTorch Domains\\nRead the PyTorch Domains documentation to learn more about domain-specific libraries\\n\\n\\n\\n\\n\\n\\n\\n                Blogs & News \\n              \\n\\n\\nPyTorch Blog\\nCatch up on the latest technical news and happenings\\n\\n\\nCommunity Blog\\nStories from the PyTorch ecosystem\\n\\n\\nVideos\\nLearn about the latest PyTorch tutorials, new, and more \\n\\nCommunity Stories\\nLearn how our community solves real, everyday machine learning problems with PyTorch\\n\\n\\nEvents\\nFind events, webinars, and podcasts\\n\\n\\n\\n\\n\\n\\n                About\\n              \\n\\n\\nPyTorch Foundation\\nLearn more about the PyTorch Foundation\\n\\n\\nGoverning Board\\n\\n\\n\\n\\n\\n\\n\\n\\n                Become a Member\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of Contents\\n\\n\\n\\n\\n\\n\\n\\n2.6 ▼\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Google Search\\n    \\n\\n\\n      Classic Search\\n    \\n\\n\\n\\n\\n\\xa0 Share Your Feedback about our new search\\n\\n\\nCommunity\\n\\nPyTorch Governance | Build + CI\\nPyTorch Contribution Guide\\nPyTorch Design Philosophy\\nPyTorch Governance | Mechanics\\nPyTorch Governance | Maintainers\\n\\nDeveloper Notes\\n\\nAutomatic Mixed Precision examples\\nAutograd mechanics\\nBroadcasting semantics\\nCPU threading and TorchScript inference\\nCUDA semantics\\nPyTorch Custom Operators Landing Page\\nDistributed Data Parallel\\nExtending PyTorch\\nExtending torch.func with autograd.Function\\nFrequently Asked Questions\\nFSDP Notes\\nGetting Started on Intel GPU\\nGradcheck mechanics\\nHIP (ROCm) semantics\\nFeatures for large-scale deployments\\nModules\\nMPS backend\\nMultiprocessing best practices\\nNumerical accuracy\\nReproducibility\\nSerialization semantics\\nWindows FAQ\\n\\nLanguage Bindings\\n\\nC++\\nJavadoc\\ntorch::deploy\\n\\nPython API\\n\\ntorch\\ntorch.nn\\ntorch.nn.functional\\ntorch.Tensor\\nTensor Attributes\\nTensor Views\\ntorch.amp\\ntorch.autograd\\ntorch.library\\ntorch.accelerator\\ntorch.cpu\\ntorch.cuda\\nUnderstanding CUDA Memory Usage\\nGenerating a Snapshot\\nUsing the visualizer\\nSnapshot API Reference\\ntorch.mps\\ntorch.xpu\\ntorch.mtia\\ntorch.mtia.memory\\nMeta device\\ntorch.backends\\ntorch.export\\ntorch.distributed\\ntorch.distributed.tensor\\ntorch.distributed.algorithms.join\\ntorch.distributed.elastic\\ntorch.distributed.fsdp\\ntorch.distributed.fsdp.fully_shard\\ntorch.distributed.tensor.parallel\\ntorch.distributed.optim\\ntorch.distributed.pipelining\\ntorch.distributed.checkpoint\\ntorch.distributions\\ntorch.compiler\\ntorch.fft\\ntorch.func\\ntorch.futures\\ntorch.fx\\ntorch.fx.experimental\\ntorch.hub\\ntorch.jit\\ntorch.linalg\\ntorch.monitor\\ntorch.signal\\ntorch.special\\ntorch.overrides\\ntorch.package\\ntorch.profiler\\ntorch.nn.init\\ntorch.nn.attention\\ntorch.onnx\\ntorch.optim\\nComplex Numbers\\nDDP Communication Hooks\\nQuantization\\nDistributed RPC Framework\\ntorch.random\\ntorch.masked\\ntorch.nested\\ntorch.Size\\ntorch.sparse\\ntorch.Storage\\ntorch.testing\\ntorch.utils\\ntorch.utils.benchmark\\ntorch.utils.bottleneck\\ntorch.utils.checkpoint\\ntorch.utils.cpp_extension\\ntorch.utils.data\\ntorch.utils.deterministic\\ntorch.utils.jit\\ntorch.utils.dlpack\\ntorch.utils.mobile_optimizer\\ntorch.utils.model_zoo\\ntorch.utils.tensorboard\\ntorch.utils.module_tracker\\nType Info\\nNamed Tensors\\nNamed Tensors operator coverage\\ntorch.__config__\\ntorch.__future__\\ntorch._logging\\nTorch Environment Variables\\n\\nLibraries\\n\\ntorchaudio\\nTorchData\\nTorchRec\\nTorchServe\\ntorchtext\\ntorchvision\\nPyTorch on XLA Devices\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n            Docs\\n          \\n         >\\n      \\ntorch.nn\\n\\n\\n\\n\\n\\n\\n\\n          Shortcuts\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntorch.nn¶\\nThese are the basic building blocks for graphs:\\n\\ntorch.nn\\n\\nContainers\\nConvolution Layers\\nPooling layers\\nPadding Layers\\nNon-linear Activations (weighted sum, nonlinearity)\\nNon-linear Activations (other)\\nNormalization Layers\\nRecurrent Layers\\nTransformer Layers\\nLinear Layers\\nDropout Layers\\nSparse Layers\\nDistance Functions\\nLoss Functions\\nVision Layers\\nShuffle Layers\\nDataParallel Layers (multi-GPU, distributed)\\nUtilities\\nQuantized Functions\\nLazy Modules Initialization\\n\\nAliases\\n\\n\\n\\n\\n\\n\\nBuffer\\nA kind of Tensor that should not be considered a model parameter.\\n\\nParameter\\nA kind of Tensor that is to be considered a module parameter.\\n\\nUninitializedParameter\\nA parameter that is not initialized.\\n\\nUninitializedBuffer\\nA buffer that is not initialized.\\n\\n\\n\\n\\nContainers¶\\n\\n\\nModule\\nBase class for all neural network modules.\\n\\nSequential\\nA sequential container.\\n\\nModuleList\\nHolds submodules in a list.\\n\\nModuleDict\\nHolds submodules in a dictionary.\\n\\nParameterList\\nHolds parameters in a list.\\n\\nParameterDict\\nHolds parameters in a dictionary.\\n\\n\\n\\nGlobal Hooks For Module\\n\\n\\nregister_module_forward_pre_hook\\nRegister a forward pre-hook common to all modules.\\n\\nregister_module_forward_hook\\nRegister a global forward hook for all the modules.\\n\\nregister_module_backward_hook\\nRegister a backward hook common to all the modules.\\n\\nregister_module_full_backward_pre_hook\\nRegister a backward pre-hook common to all the modules.\\n\\nregister_module_full_backward_hook\\nRegister a backward hook common to all the modules.\\n\\nregister_module_buffer_registration_hook\\nRegister a buffer registration hook common to all modules.\\n\\nregister_module_module_registration_hook\\nRegister a module registration hook common to all modules.\\n\\nregister_module_parameter_registration_hook\\nRegister a parameter registration hook common to all modules.\\n\\n\\n\\n\\n\\nConvolution Layers¶\\n\\n\\nnn.Conv1d\\nApplies a 1D convolution over an input signal composed of several input planes.\\n\\nnn.Conv2d\\nApplies a 2D convolution over an input signal composed of several input planes.\\n\\nnn.Conv3d\\nApplies a 3D convolution over an input signal composed of several input planes.\\n\\nnn.ConvTranspose1d\\nApplies a 1D transposed convolution operator over an input image composed of several input planes.\\n\\nnn.ConvTranspose2d\\nApplies a 2D transposed convolution operator over an input image composed of several input planes.\\n\\nnn.ConvTranspose3d\\nApplies a 3D transposed convolution operator over an input image composed of several input planes.\\n\\nnn.LazyConv1d\\nA torch.nn.Conv1d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConv2d\\nA torch.nn.Conv2d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConv3d\\nA torch.nn.Conv3d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConvTranspose1d\\nA torch.nn.ConvTranspose1d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConvTranspose2d\\nA torch.nn.ConvTranspose2d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConvTranspose3d\\nA torch.nn.ConvTranspose3d module with lazy initialization of the in_channels argument.\\n\\nnn.Unfold\\nExtracts sliding local blocks from a batched input tensor.\\n\\nnn.Fold\\nCombines an array of sliding local blocks into a large containing tensor.\\n\\n\\n\\n\\n\\nPooling layers¶\\n\\n\\nnn.MaxPool1d\\nApplies a 1D max pooling over an input signal composed of several input planes.\\n\\nnn.MaxPool2d\\nApplies a 2D max pooling over an input signal composed of several input planes.\\n\\nnn.MaxPool3d\\nApplies a 3D max pooling over an input signal composed of several input planes.\\n\\nnn.MaxUnpool1d\\nComputes a partial inverse of MaxPool1d.\\n\\nnn.MaxUnpool2d\\nComputes a partial inverse of MaxPool2d.\\n\\nnn.MaxUnpool3d\\nComputes a partial inverse of MaxPool3d.\\n\\nnn.AvgPool1d\\nApplies a 1D average pooling over an input signal composed of several input planes.\\n\\nnn.AvgPool2d\\nApplies a 2D average pooling over an input signal composed of several input planes.\\n\\nnn.AvgPool3d\\nApplies a 3D average pooling over an input signal composed of several input planes.\\n\\nnn.FractionalMaxPool2d\\nApplies a 2D fractional max pooling over an input signal composed of several input planes.\\n\\nnn.FractionalMaxPool3d\\nApplies a 3D fractional max pooling over an input signal composed of several input planes.\\n\\nnn.LPPool1d\\nApplies a 1D power-average pooling over an input signal composed of several input planes.\\n\\nnn.LPPool2d\\nApplies a 2D power-average pooling over an input signal composed of several input planes.\\n\\nnn.LPPool3d\\nApplies a 3D power-average pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveMaxPool1d\\nApplies a 1D adaptive max pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveMaxPool2d\\nApplies a 2D adaptive max pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveMaxPool3d\\nApplies a 3D adaptive max pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveAvgPool1d\\nApplies a 1D adaptive average pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveAvgPool2d\\nApplies a 2D adaptive average pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveAvgPool3d\\nApplies a 3D adaptive average pooling over an input signal composed of several input planes.\\n\\n\\n\\n\\n\\nPadding Layers¶\\n\\n\\nnn.ReflectionPad1d\\nPads the input tensor using the reflection of the input boundary.\\n\\nnn.ReflectionPad2d\\nPads the input tensor using the reflection of the input boundary.\\n\\nnn.ReflectionPad3d\\nPads the input tensor using the reflection of the input boundary.\\n\\nnn.ReplicationPad1d\\nPads the input tensor using replication of the input boundary.\\n\\nnn.ReplicationPad2d\\nPads the input tensor using replication of the input boundary.\\n\\nnn.ReplicationPad3d\\nPads the input tensor using replication of the input boundary.\\n\\nnn.ZeroPad1d\\nPads the input tensor boundaries with zero.\\n\\nnn.ZeroPad2d\\nPads the input tensor boundaries with zero.\\n\\nnn.ZeroPad3d\\nPads the input tensor boundaries with zero.\\n\\nnn.ConstantPad1d\\nPads the input tensor boundaries with a constant value.\\n\\nnn.ConstantPad2d\\nPads the input tensor boundaries with a constant value.\\n\\nnn.ConstantPad3d\\nPads the input tensor boundaries with a constant value.\\n\\nnn.CircularPad1d\\nPads the input tensor using circular padding of the input boundary.\\n\\nnn.CircularPad2d\\nPads the input tensor using circular padding of the input boundary.\\n\\nnn.CircularPad3d\\nPads the input tensor using circular padding of the input boundary.\\n\\n\\n\\n\\n\\nNon-linear Activations (weighted sum, nonlinearity)¶\\n\\n\\nnn.ELU\\nApplies the Exponential Linear Unit (ELU) function, element-wise.\\n\\nnn.Hardshrink\\nApplies the Hard Shrinkage (Hardshrink) function element-wise.\\n\\nnn.Hardsigmoid\\nApplies the Hardsigmoid function element-wise.\\n\\nnn.Hardtanh\\nApplies the HardTanh function element-wise.\\n\\nnn.Hardswish\\nApplies the Hardswish function, element-wise.\\n\\nnn.LeakyReLU\\nApplies the LeakyReLU function element-wise.\\n\\nnn.LogSigmoid\\nApplies the Logsigmoid function element-wise.\\n\\nnn.MultiheadAttention\\nAllows the model to jointly attend to information from different representation subspaces.\\n\\nnn.PReLU\\nApplies the element-wise PReLU function.\\n\\nnn.ReLU\\nApplies the rectified linear unit function element-wise.\\n\\nnn.ReLU6\\nApplies the ReLU6 function element-wise.\\n\\nnn.RReLU\\nApplies the randomized leaky rectified linear unit function, element-wise.\\n\\nnn.SELU\\nApplies the SELU function element-wise.\\n\\nnn.CELU\\nApplies the CELU function element-wise.\\n\\nnn.GELU\\nApplies the Gaussian Error Linear Units function.\\n\\nnn.Sigmoid\\nApplies the Sigmoid function element-wise.\\n\\nnn.SiLU\\nApplies the Sigmoid Linear Unit (SiLU) function, element-wise.\\n\\nnn.Mish\\nApplies the Mish function, element-wise.\\n\\nnn.Softplus\\nApplies the Softplus function element-wise.\\n\\nnn.Softshrink\\nApplies the soft shrinkage function element-wise.\\n\\nnn.Softsign\\nApplies the element-wise Softsign function.\\n\\nnn.Tanh\\nApplies the Hyperbolic Tangent (Tanh) function element-wise.\\n\\nnn.Tanhshrink\\nApplies the element-wise Tanhshrink function.\\n\\nnn.Threshold\\nThresholds each element of the input Tensor.\\n\\nnn.GLU\\nApplies the gated linear unit function.\\n\\n\\n\\n\\n\\nNon-linear Activations (other)¶\\n\\n\\nnn.Softmin\\nApplies the Softmin function to an n-dimensional input Tensor.\\n\\nnn.Softmax\\nApplies the Softmax function to an n-dimensional input Tensor.\\n\\nnn.Softmax2d\\nApplies SoftMax over features to each spatial location.\\n\\nnn.LogSoftmax\\nApplies the log\\u2061(Softmax(x))\\\\log(\\\\text{Softmax}(x))log(Softmax(x)) function to an n-dimensional input Tensor.\\n\\nnn.AdaptiveLogSoftmaxWithLoss\\nEfficient softmax approximation.\\n\\n\\n\\n\\n\\nNormalization Layers¶\\n\\n\\nnn.BatchNorm1d\\nApplies Batch Normalization over a 2D or 3D input.\\n\\nnn.BatchNorm2d\\nApplies Batch Normalization over a 4D input.\\n\\nnn.BatchNorm3d\\nApplies Batch Normalization over a 5D input.\\n\\nnn.LazyBatchNorm1d\\nA torch.nn.BatchNorm1d module with lazy initialization.\\n\\nnn.LazyBatchNorm2d\\nA torch.nn.BatchNorm2d module with lazy initialization.\\n\\nnn.LazyBatchNorm3d\\nA torch.nn.BatchNorm3d module with lazy initialization.\\n\\nnn.GroupNorm\\nApplies Group Normalization over a mini-batch of inputs.\\n\\nnn.SyncBatchNorm\\nApplies Batch Normalization over a N-Dimensional input.\\n\\nnn.InstanceNorm1d\\nApplies Instance Normalization.\\n\\nnn.InstanceNorm2d\\nApplies Instance Normalization.\\n\\nnn.InstanceNorm3d\\nApplies Instance Normalization.\\n\\nnn.LazyInstanceNorm1d\\nA torch.nn.InstanceNorm1d module with lazy initialization of the num_features argument.\\n\\nnn.LazyInstanceNorm2d\\nA torch.nn.InstanceNorm2d module with lazy initialization of the num_features argument.\\n\\nnn.LazyInstanceNorm3d\\nA torch.nn.InstanceNorm3d module with lazy initialization of the num_features argument.\\n\\nnn.LayerNorm\\nApplies Layer Normalization over a mini-batch of inputs.\\n\\nnn.LocalResponseNorm\\nApplies local response normalization over an input signal.\\n\\nnn.RMSNorm\\nApplies Root Mean Square Layer Normalization over a mini-batch of inputs.\\n\\n\\n\\n\\n\\nRecurrent Layers¶\\n\\n\\nnn.RNNBase\\nBase class for RNN modules (RNN, LSTM, GRU).\\n\\nnn.RNN\\nApply a multi-layer Elman RNN with tanh\\u2061\\\\tanhtanh or ReLU\\\\text{ReLU}ReLU non-linearity to an input sequence.\\n\\nnn.LSTM\\nApply a multi-layer long short-term memory (LSTM) RNN to an input sequence.\\n\\nnn.GRU\\nApply a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\\n\\nnn.RNNCell\\nAn Elman RNN cell with tanh or ReLU non-linearity.\\n\\nnn.LSTMCell\\nA long short-term memory (LSTM) cell.\\n\\nnn.GRUCell\\nA gated recurrent unit (GRU) cell.\\n\\n\\n\\n\\n\\nTransformer Layers¶\\n\\n\\nnn.Transformer\\nA transformer model.\\n\\nnn.TransformerEncoder\\nTransformerEncoder is a stack of N encoder layers.\\n\\nnn.TransformerDecoder\\nTransformerDecoder is a stack of N decoder layers.\\n\\nnn.TransformerEncoderLayer\\nTransformerEncoderLayer is made up of self-attn and feedforward network.\\n\\nnn.TransformerDecoderLayer\\nTransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\\n\\n\\n\\n\\n\\nLinear Layers¶\\n\\n\\nnn.Identity\\nA placeholder identity operator that is argument-insensitive.\\n\\nnn.Linear\\nApplies an affine linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b.\\n\\nnn.Bilinear\\nApplies a bilinear transformation to the incoming data: y=x1TAx2+by = x_1^T A x_2 + by=x1T\\u200bAx2\\u200b+b.\\n\\nnn.LazyLinear\\nA torch.nn.Linear module where in_features is inferred.\\n\\n\\n\\n\\n\\nDropout Layers¶\\n\\n\\nnn.Dropout\\nDuring training, randomly zeroes some of the elements of the input tensor with probability p.\\n\\nnn.Dropout1d\\nRandomly zero out entire channels.\\n\\nnn.Dropout2d\\nRandomly zero out entire channels.\\n\\nnn.Dropout3d\\nRandomly zero out entire channels.\\n\\nnn.AlphaDropout\\nApplies Alpha Dropout over the input.\\n\\nnn.FeatureAlphaDropout\\nRandomly masks out entire channels.\\n\\n\\n\\n\\n\\nSparse Layers¶\\n\\n\\nnn.Embedding\\nA simple lookup table that stores embeddings of a fixed dictionary and size.\\n\\nnn.EmbeddingBag\\nCompute sums or means of \\'bags\\' of embeddings, without instantiating the intermediate embeddings.\\n\\n\\n\\n\\n\\nDistance Functions¶\\n\\n\\nnn.CosineSimilarity\\nReturns cosine similarity between x1x_1x1\\u200b and x2x_2x2\\u200b, computed along dim.\\n\\nnn.PairwiseDistance\\nComputes the pairwise distance between input vectors, or between columns of input matrices.\\n\\n\\n\\n\\n\\nLoss Functions¶\\n\\n\\nnn.L1Loss\\nCreates a criterion that measures the mean absolute error (MAE) between each element in the input xxx and target yyy.\\n\\nnn.MSELoss\\nCreates a criterion that measures the mean squared error (squared L2 norm) between each element in the input xxx and target yyy.\\n\\nnn.CrossEntropyLoss\\nThis criterion computes the cross entropy loss between input logits and target.\\n\\nnn.CTCLoss\\nThe Connectionist Temporal Classification loss.\\n\\nnn.NLLLoss\\nThe negative log likelihood loss.\\n\\nnn.PoissonNLLLoss\\nNegative log likelihood loss with Poisson distribution of target.\\n\\nnn.GaussianNLLLoss\\nGaussian negative log likelihood loss.\\n\\nnn.KLDivLoss\\nThe Kullback-Leibler divergence loss.\\n\\nnn.BCELoss\\nCreates a criterion that measures the Binary Cross Entropy between the target and the input probabilities:\\n\\nnn.BCEWithLogitsLoss\\nThis loss combines a Sigmoid layer and the BCELoss in one single class.\\n\\nnn.MarginRankingLoss\\nCreates a criterion that measures the loss given inputs x1x1x1, x2x2x2, two 1D mini-batch or 0D Tensors, and a label 1D mini-batch or 0D Tensor yyy (containing 1 or -1).\\n\\nnn.HingeEmbeddingLoss\\nMeasures the loss given an input tensor xxx and a labels tensor yyy (containing 1 or -1).\\n\\nnn.MultiLabelMarginLoss\\nCreates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input xxx (a 2D mini-batch Tensor) and output yyy (which is a 2D Tensor of target class indices).\\n\\nnn.HuberLoss\\nCreates a criterion that uses a squared term if the absolute element-wise error falls below delta and a delta-scaled L1 term otherwise.\\n\\nnn.SmoothL1Loss\\nCreates a criterion that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise.\\n\\nnn.SoftMarginLoss\\nCreates a criterion that optimizes a two-class classification logistic loss between input tensor xxx and target tensor yyy (containing 1 or -1).\\n\\nnn.MultiLabelSoftMarginLoss\\nCreates a criterion that optimizes a multi-label one-versus-all loss based on max-entropy, between input xxx and target yyy of size (N,C)(N, C)(N,C).\\n\\nnn.CosineEmbeddingLoss\\nCreates a criterion that measures the loss given input tensors x1x_1x1\\u200b, x2x_2x2\\u200b and a Tensor label yyy with values 1 or -1.\\n\\nnn.MultiMarginLoss\\nCreates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input xxx (a 2D mini-batch Tensor) and output yyy (which is a 1D tensor of target class indices, 0≤y≤x.size(1)−10 \\\\leq y \\\\leq \\\\text{x.size}(1)-10≤y≤x.size(1)−1):\\n\\nnn.TripletMarginLoss\\nCreates a criterion that measures the triplet loss given an input tensors x1x1x1, x2x2x2, x3x3x3 and a margin with a value greater than 000.\\n\\nnn.TripletMarginWithDistanceLoss\\nCreates a criterion that measures the triplet loss given input tensors aaa, ppp, and nnn (representing anchor, positive, and negative examples, respectively), and a nonnegative, real-valued function (\"distance function\") used to compute the relationship between the anchor and positive example (\"positive distance\") and the anchor and negative example (\"negative distance\").\\n\\n\\n\\n\\n\\nVision Layers¶\\n\\n\\nnn.PixelShuffle\\nRearrange elements in a tensor according to an upscaling factor.\\n\\nnn.PixelUnshuffle\\nReverse the PixelShuffle operation.\\n\\nnn.Upsample\\nUpsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.\\n\\nnn.UpsamplingNearest2d\\nApplies a 2D nearest neighbor upsampling to an input signal composed of several input channels.\\n\\nnn.UpsamplingBilinear2d\\nApplies a 2D bilinear upsampling to an input signal composed of several input channels.\\n\\n\\n\\n\\n\\nShuffle Layers¶\\n\\n\\nnn.ChannelShuffle\\nDivides and rearranges the channels in a tensor.\\n\\n\\n\\n\\n\\nDataParallel Layers (multi-GPU, distributed)¶\\n\\n\\nnn.DataParallel\\nImplements data parallelism at the module level.\\n\\nnn.parallel.DistributedDataParallel\\nImplement distributed data parallelism based on torch.distributed at module level.\\n\\n\\n\\n\\n\\nUtilities¶\\nFrom the torch.nn.utils module:\\nUtility functions to clip parameter gradients.\\n\\n\\nclip_grad_norm_\\nClip the gradient norm of an iterable of parameters.\\n\\nclip_grad_norm\\nClip the gradient norm of an iterable of parameters.\\n\\nclip_grad_value_\\nClip the gradients of an iterable of parameters at specified value.\\n\\nget_total_norm\\nCompute the norm of an iterable of tensors.\\n\\nclip_grads_with_norm_\\nScale the gradients of an iterable of parameters given a pre-calculated total norm and desired max norm.\\n\\n\\n\\nUtility functions to flatten and unflatten Module parameters to and from a single vector.\\n\\n\\nparameters_to_vector\\nFlatten an iterable of parameters into a single vector.\\n\\nvector_to_parameters\\nCopy slices of a vector into an iterable of parameters.\\n\\n\\n\\nUtility functions to fuse Modules with BatchNorm modules.\\n\\n\\nfuse_conv_bn_eval\\nFuse a convolutional module and a BatchNorm module into a single, new convolutional module.\\n\\nfuse_conv_bn_weights\\nFuse convolutional module parameters and BatchNorm module parameters into new convolutional module parameters.\\n\\nfuse_linear_bn_eval\\nFuse a linear module and a BatchNorm module into a single, new linear module.\\n\\nfuse_linear_bn_weights\\nFuse linear module parameters and BatchNorm module parameters into new linear module parameters.\\n\\n\\n\\nUtility functions to convert Module parameter memory formats.\\n\\n\\nconvert_conv2d_weight_memory_format\\nConvert memory_format of nn.Conv2d.weight to memory_format.\\n\\nconvert_conv3d_weight_memory_format\\nConvert memory_format of nn.Conv3d.weight to memory_format The conversion recursively applies to nested nn.Module, including module.\\n\\n\\n\\nUtility functions to apply and remove weight normalization from Module parameters.\\n\\n\\nweight_norm\\nApply weight normalization to a parameter in the given module.\\n\\nremove_weight_norm\\nRemove the weight normalization reparameterization from a module.\\n\\nspectral_norm\\nApply spectral normalization to a parameter in the given module.\\n\\nremove_spectral_norm\\nRemove the spectral normalization reparameterization from a module.\\n\\n\\n\\nUtility functions for initializing Module parameters.\\n\\n\\nskip_init\\nGiven a module class object and args / kwargs, instantiate the module without initializing parameters / buffers.\\n\\n\\n\\nUtility classes and functions for pruning Module parameters.\\n\\n\\nprune.BasePruningMethod\\nAbstract base class for creation of new pruning techniques.\\n\\nprune.PruningContainer\\nContainer holding a sequence of pruning methods for iterative pruning.\\n\\nprune.Identity\\nUtility pruning method that does not prune any units but generates the pruning parametrization with a mask of ones.\\n\\nprune.RandomUnstructured\\nPrune (currently unpruned) units in a tensor at random.\\n\\nprune.L1Unstructured\\nPrune (currently unpruned) units in a tensor by zeroing out the ones with the lowest L1-norm.\\n\\nprune.RandomStructured\\nPrune entire (currently unpruned) channels in a tensor at random.\\n\\nprune.LnStructured\\nPrune entire (currently unpruned) channels in a tensor based on their Ln-norm.\\n\\nprune.CustomFromMask\\n\\n\\nprune.identity\\nApply pruning reparametrization without pruning any units.\\n\\nprune.random_unstructured\\nPrune tensor by removing random (currently unpruned) units.\\n\\nprune.l1_unstructured\\nPrune tensor by removing units with the lowest L1-norm.\\n\\nprune.random_structured\\nPrune tensor by removing random channels along the specified dimension.\\n\\nprune.ln_structured\\nPrune tensor by removing channels with the lowest Ln-norm along the specified dimension.\\n\\nprune.global_unstructured\\nGlobally prunes tensors corresponding to all parameters in parameters by applying the specified pruning_method.\\n\\nprune.custom_from_mask\\nPrune tensor corresponding to parameter called name in module by applying the pre-computed mask in mask.\\n\\nprune.remove\\nRemove the pruning reparameterization from a module and the pruning method from the forward hook.\\n\\nprune.is_pruned\\nCheck if a module is pruned by looking for pruning pre-hooks.\\n\\n\\n\\nParametrizations implemented using the new parametrization functionality\\nin torch.nn.utils.parameterize.register_parametrization().\\n\\n\\nparametrizations.orthogonal\\nApply an orthogonal or unitary parametrization to a matrix or a batch of matrices.\\n\\nparametrizations.weight_norm\\nApply weight normalization to a parameter in the given module.\\n\\nparametrizations.spectral_norm\\nApply spectral normalization to a parameter in the given module.\\n\\n\\n\\nUtility functions to parametrize Tensors on existing Modules.\\nNote that these functions can be used to parametrize a given Parameter\\nor Buffer given a specific function that maps from an input space to the\\nparametrized space. They are not parameterizations that would transform\\nan object into a parameter. See the\\nParametrizations tutorial\\nfor more information on how to implement your own parametrizations.\\n\\n\\nparametrize.register_parametrization\\nRegister a parametrization to a tensor in a module.\\n\\nparametrize.remove_parametrizations\\nRemove the parametrizations on a tensor in a module.\\n\\nparametrize.cached\\nContext manager that enables the caching system within parametrizations registered with register_parametrization().\\n\\nparametrize.is_parametrized\\nDetermine if a module has a parametrization.\\n\\n\\n\\n\\n\\nparametrize.ParametrizationList\\nA sequential container that holds and manages the original parameters or buffers of a parametrized torch.nn.Module.\\n\\n\\n\\nUtility functions to call a given Module in a stateless manner.\\n\\n\\nstateless.functional_call\\nPerform a functional call on the module by replacing the module parameters and buffers with the provided ones.\\n\\n\\n\\nUtility functions in other modules\\n\\n\\nnn.utils.rnn.PackedSequence\\nHolds the data and list of batch_sizes of a packed sequence.\\n\\nnn.utils.rnn.pack_padded_sequence\\nPacks a Tensor containing padded sequences of variable length.\\n\\nnn.utils.rnn.pad_packed_sequence\\nPad a packed batch of variable length sequences.\\n\\nnn.utils.rnn.pad_sequence\\nPad a list of variable length Tensors with padding_value.\\n\\nnn.utils.rnn.pack_sequence\\nPacks a list of variable length Tensors.\\n\\nnn.utils.rnn.unpack_sequence\\nUnpack PackedSequence into a list of variable length Tensors.\\n\\nnn.utils.rnn.unpad_sequence\\nUnpad padded Tensor into a list of variable length Tensors.\\n\\n\\n\\n\\n\\nnn.Flatten\\nFlattens a contiguous range of dims into a tensor.\\n\\nnn.Unflatten\\nUnflattens a tensor dim expanding it to a desired shape.\\n\\n\\n\\n\\n\\nQuantized Functions¶\\nQuantization refers to techniques for performing computations and storing tensors at lower bitwidths than\\nfloating point precision. PyTorch supports both per tensor and per channel asymmetric linear quantization. To learn more how to use quantized functions in PyTorch, please refer to the Quantization documentation.\\n\\n\\nLazy Modules Initialization¶\\n\\n\\nnn.modules.lazy.LazyModuleMixin\\nA mixin for modules that lazily initialize parameters, also known as \"lazy modules\".\\n\\n\\n\\n\\nAliases¶\\nThe following are aliases to their counterparts in torch.nn:\\n\\n\\nnn.modules.normalization.RMSNorm\\nApplies Root Mean Square Layer Normalization over a mini-batch of inputs.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNext \\n Previous\\n\\n\\n\\n\\n        © Copyright 2024, PyTorch Contributors.\\n\\n    \\n\\n\\n        Built with Sphinx using a theme provided by Read the Docs.\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\ntorch.nn\\nContainers\\n\\n\\nConvolution Layers\\nPooling layers\\nPadding Layers\\nNon-linear Activations (weighted sum, nonlinearity)\\nNon-linear Activations (other)\\nNormalization Layers\\nRecurrent Layers\\nTransformer Layers\\nLinear Layers\\nDropout Layers\\nSparse Layers\\nDistance Functions\\nLoss Functions\\nVision Layers\\nShuffle Layers\\nDataParallel Layers (multi-GPU, distributed)\\nUtilities\\n\\n\\nQuantized Functions\\nLazy Modules Initialization\\nAliases\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDocs\\nAccess comprehensive developer documentation for PyTorch\\nView Docs\\n\\n\\nTutorials\\nGet in-depth tutorials for beginners and advanced developers\\nView Tutorials\\n\\n\\nResources\\nFind development resources and get your questions answered\\nView Resources\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPyTorch\\nGet Started\\nFeatures\\nEcosystem\\nBlog\\nContributing\\n\\n\\n\\n\\nResources\\nTutorials\\nDocs\\nDiscuss\\nGithub Issues\\nBrand Guidelines\\n\\n\\n\\n\\nStay up to date\\nFacebook\\nTwitter\\nYouTube\\nLinkedIn\\n\\n\\n\\n\\nPyTorch Podcasts\\nSpotify\\nApple\\nGoogle\\nAmazon\\n\\n\\n\\n\\n\\nTerms\\n|\\nPrivacy\\n\\n\\n\\n© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.\\n          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see\\n          www.linuxfoundation.org/policies/. The PyTorch Foundation supports the PyTorch open source\\n          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,\\n          please see www.lfprojects.org/policies/.\\n\\n\\n\\n\\n\\nTo analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: Cookies Policy.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLearn\\n\\n\\n\\nGet Started\\n\\n\\nTutorials\\n\\n\\nLearn the Basics\\n\\n\\nPyTorch Recipes\\n\\n\\nIntroduction to PyTorch - YouTube Series\\n\\n\\n\\nEcosystem\\n\\n\\n\\nTools\\n\\n\\nCommunity\\n\\n\\nForums\\n\\n\\nDeveloper Resources\\n\\n\\nContributor Awards - 2023\\n\\n\\n\\nEdge\\n\\n\\n\\nAbout PyTorch Edge\\n\\n\\nExecuTorch\\n\\n\\n\\nDocs\\n\\n\\n\\nPyTorch\\n\\n\\nPyTorch Domains\\n\\n\\n\\nBlog & News\\n\\n\\n\\nPyTorch Blog\\n\\n\\nCommunity Blog\\n\\n\\nVideos\\n\\n\\nCommunity Stories\\n\\n\\nEvents\\n\\n\\n\\nAbout\\n\\n\\n\\nPyTorch Foundation\\n\\n\\nGoverning Board\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content=\"torch.nn — PyTorch 2.6 documentation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Learn\\n              \\n\\n\\nGet Started\\nRun PyTorch locally or get started quickly with one of the supported cloud platforms\\n\\n\\nTutorials\\nWhats new in PyTorch tutorials\\n\\n\\nLearn the Basics\\nFamiliarize yourself with PyTorch concepts and modules\\n\\n\\nPyTorch Recipes\\nBite-size, ready-to-deploy PyTorch code examples\\n\\n\\nIntro to PyTorch - YouTube Series\\nMaster PyTorch basics with our engaging YouTube tutorial series\\n\\n\\n\\n\\n\\n\\n\\n                Ecosystem\\n              \\n\\n\\nTools\\nLearn about the tools and frameworks in the PyTorch Ecosystem\\n\\n\\nCommunity\\nJoin the PyTorch developer community to contribute, learn, and get your questions answered\\n\\n\\nForums\\nA place to discuss PyTorch code, issues, install, research\\n\\n\\nDeveloper Resources\\nFind resources and get questions answered\\n\\n\\nContributor Awards - 2023\\nAward winners announced at this year's PyTorch Conference\\n\\n\\n\\n\\n\\n\\n\\n                Edge\\n              \\n\\n\\nAbout PyTorch Edge\\nBuild innovative and privacy-aware AI experiences for edge devices\\n\\n\\nExecuTorch\\nEnd-to-end solution for enabling on-device inference capabilities across mobile and edge devices\\n\\n\\n\\n\\n\\n\\n\\n                Docs\\n              \\n\\n\\nPyTorch\\nExplore the documentation for comprehensive guidance on how to use PyTorch\\n\\n\\nPyTorch Domains\\nRead the PyTorch Domains documentation to learn more about domain-specific libraries\\n\\n\\n\\n\\n\\n\\n\\n                Blogs & News \\n              \\n\\n\\nPyTorch Blog\\nCatch up on the latest technical news and happenings\\n\\n\\nCommunity Blog\\nStories from the PyTorch ecosystem\\n\\n\\nVideos\\nLearn about the latest PyTorch tutorials, new, and more \\n\\nCommunity Stories\\nLearn how our community solves real, everyday machine learning problems with PyTorch\\n\\n\\nEvents\\nFind events, webinars, and podcasts\\n\\n\\n\\n\\n\\n\\n                About\\n              \\n\\n\\nPyTorch Foundation\\nLearn more about the PyTorch Foundation\\n\\n\\nGoverning Board\\n\\n\\n\\n\\n\\n\\n\\n\\n                Become a Member\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of Contents\\n\\n\\n\\n\\n\\n\\n\\n2.6 ▼\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Google Search\\n    \\n\\n\\n      Classic Search\\n    \\n\\n\\n\\n\\n\\xa0 Share Your Feedback about our new search\\n\\n\\nCommunity\\n\\nPyTorch Governance | Build + CI\\nPyTorch Contribution Guide\\nPyTorch Design Philosophy\\nPyTorch Governance | Mechanics\\nPyTorch Governance | Maintainers\\n\\nDeveloper Notes\"),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='PyTorch Foundation\\nLearn more about the PyTorch Foundation\\n\\n\\nGoverning Board\\n\\n\\n\\n\\n\\n\\n\\n\\n                Become a Member\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of Contents\\n\\n\\n\\n\\n\\n\\n\\n2.6 ▼\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Google Search\\n    \\n\\n\\n      Classic Search\\n    \\n\\n\\n\\n\\n\\xa0 Share Your Feedback about our new search\\n\\n\\nCommunity\\n\\nPyTorch Governance | Build + CI\\nPyTorch Contribution Guide\\nPyTorch Design Philosophy\\nPyTorch Governance | Mechanics\\nPyTorch Governance | Maintainers\\n\\nDeveloper Notes\\n\\nAutomatic Mixed Precision examples\\nAutograd mechanics\\nBroadcasting semantics\\nCPU threading and TorchScript inference\\nCUDA semantics\\nPyTorch Custom Operators Landing Page\\nDistributed Data Parallel\\nExtending PyTorch\\nExtending torch.func with autograd.Function\\nFrequently Asked Questions\\nFSDP Notes\\nGetting Started on Intel GPU\\nGradcheck mechanics\\nHIP (ROCm) semantics\\nFeatures for large-scale deployments\\nModules\\nMPS backend\\nMultiprocessing best practices\\nNumerical accuracy\\nReproducibility\\nSerialization semantics\\nWindows FAQ\\n\\nLanguage Bindings\\n\\nC++\\nJavadoc\\ntorch::deploy\\n\\nPython API'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='Language Bindings\\n\\nC++\\nJavadoc\\ntorch::deploy\\n\\nPython API\\n\\ntorch\\ntorch.nn\\ntorch.nn.functional\\ntorch.Tensor\\nTensor Attributes\\nTensor Views\\ntorch.amp\\ntorch.autograd\\ntorch.library\\ntorch.accelerator\\ntorch.cpu\\ntorch.cuda\\nUnderstanding CUDA Memory Usage\\nGenerating a Snapshot\\nUsing the visualizer\\nSnapshot API Reference\\ntorch.mps\\ntorch.xpu\\ntorch.mtia\\ntorch.mtia.memory\\nMeta device\\ntorch.backends\\ntorch.export\\ntorch.distributed\\ntorch.distributed.tensor\\ntorch.distributed.algorithms.join\\ntorch.distributed.elastic\\ntorch.distributed.fsdp\\ntorch.distributed.fsdp.fully_shard\\ntorch.distributed.tensor.parallel\\ntorch.distributed.optim\\ntorch.distributed.pipelining\\ntorch.distributed.checkpoint\\ntorch.distributions\\ntorch.compiler\\ntorch.fft\\ntorch.func\\ntorch.futures\\ntorch.fx\\ntorch.fx.experimental\\ntorch.hub\\ntorch.jit\\ntorch.linalg\\ntorch.monitor\\ntorch.signal\\ntorch.special\\ntorch.overrides\\ntorch.package\\ntorch.profiler\\ntorch.nn.init\\ntorch.nn.attention\\ntorch.onnx\\ntorch.optim\\nComplex Numbers\\nDDP Communication Hooks\\nQuantization\\nDistributed RPC Framework\\ntorch.random\\ntorch.masked\\ntorch.nested\\ntorch.Size\\ntorch.sparse\\ntorch.Storage\\ntorch.testing\\ntorch.utils\\ntorch.utils.benchmark\\ntorch.utils.bottleneck\\ntorch.utils.checkpoint\\ntorch.utils.cpp_extension\\ntorch.utils.data\\ntorch.utils.deterministic\\ntorch.utils.jit\\ntorch.utils.dlpack\\ntorch.utils.mobile_optimizer\\ntorch.utils.model_zoo\\ntorch.utils.tensorboard\\ntorch.utils.module_tracker\\nType Info\\nNamed Tensors\\nNamed Tensors operator coverage\\ntorch.__config__\\ntorch.__future__\\ntorch._logging\\nTorch Environment Variables\\n\\nLibraries\\n\\ntorchaudio\\nTorchData\\nTorchRec\\nTorchServe\\ntorchtext\\ntorchvision\\nPyTorch on XLA Devices\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n            Docs\\n          \\n         >\\n      \\ntorch.nn\\n\\n\\n\\n\\n\\n\\n\\n          Shortcuts\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntorch.nn¶\\nThese are the basic building blocks for graphs:\\n\\ntorch.nn\\n\\nContainers\\nConvolution Layers\\nPooling layers\\nPadding Layers\\nNon-linear Activations (weighted sum, nonlinearity)\\nNon-linear Activations (other)\\nNormalization Layers\\nRecurrent Layers\\nTransformer Layers\\nLinear Layers\\nDropout Layers\\nSparse Layers\\nDistance Functions\\nLoss Functions\\nVision Layers\\nShuffle Layers\\nDataParallel Layers (multi-GPU, distributed)\\nUtilities\\nQuantized Functions\\nLazy Modules Initialization\\n\\nAliases\\n\\n\\n\\n\\n\\n\\nBuffer\\nA kind of Tensor that should not be considered a model parameter.\\n\\nParameter\\nA kind of Tensor that is to be considered a module parameter.\\n\\nUninitializedParameter\\nA parameter that is not initialized.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='Aliases\\n\\n\\n\\n\\n\\n\\nBuffer\\nA kind of Tensor that should not be considered a model parameter.\\n\\nParameter\\nA kind of Tensor that is to be considered a module parameter.\\n\\nUninitializedParameter\\nA parameter that is not initialized.\\n\\nUninitializedBuffer\\nA buffer that is not initialized.\\n\\n\\n\\n\\nContainers¶\\n\\n\\nModule\\nBase class for all neural network modules.\\n\\nSequential\\nA sequential container.\\n\\nModuleList\\nHolds submodules in a list.\\n\\nModuleDict\\nHolds submodules in a dictionary.\\n\\nParameterList\\nHolds parameters in a list.\\n\\nParameterDict\\nHolds parameters in a dictionary.\\n\\n\\n\\nGlobal Hooks For Module\\n\\n\\nregister_module_forward_pre_hook\\nRegister a forward pre-hook common to all modules.\\n\\nregister_module_forward_hook\\nRegister a global forward hook for all the modules.\\n\\nregister_module_backward_hook\\nRegister a backward hook common to all the modules.\\n\\nregister_module_full_backward_pre_hook\\nRegister a backward pre-hook common to all the modules.\\n\\nregister_module_full_backward_hook\\nRegister a backward hook common to all the modules.\\n\\nregister_module_buffer_registration_hook\\nRegister a buffer registration hook common to all modules.\\n\\nregister_module_module_registration_hook\\nRegister a module registration hook common to all modules.\\n\\nregister_module_parameter_registration_hook\\nRegister a parameter registration hook common to all modules.\\n\\n\\n\\n\\n\\nConvolution Layers¶\\n\\n\\nnn.Conv1d\\nApplies a 1D convolution over an input signal composed of several input planes.\\n\\nnn.Conv2d\\nApplies a 2D convolution over an input signal composed of several input planes.\\n\\nnn.Conv3d\\nApplies a 3D convolution over an input signal composed of several input planes.\\n\\nnn.ConvTranspose1d\\nApplies a 1D transposed convolution operator over an input image composed of several input planes.\\n\\nnn.ConvTranspose2d\\nApplies a 2D transposed convolution operator over an input image composed of several input planes.\\n\\nnn.ConvTranspose3d\\nApplies a 3D transposed convolution operator over an input image composed of several input planes.\\n\\nnn.LazyConv1d\\nA torch.nn.Conv1d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConv2d\\nA torch.nn.Conv2d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConv3d\\nA torch.nn.Conv3d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConvTranspose1d\\nA torch.nn.ConvTranspose1d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConvTranspose2d\\nA torch.nn.ConvTranspose2d module with lazy initialization of the in_channels argument.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='nn.LazyConv2d\\nA torch.nn.Conv2d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConv3d\\nA torch.nn.Conv3d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConvTranspose1d\\nA torch.nn.ConvTranspose1d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConvTranspose2d\\nA torch.nn.ConvTranspose2d module with lazy initialization of the in_channels argument.\\n\\nnn.LazyConvTranspose3d\\nA torch.nn.ConvTranspose3d module with lazy initialization of the in_channels argument.\\n\\nnn.Unfold\\nExtracts sliding local blocks from a batched input tensor.\\n\\nnn.Fold\\nCombines an array of sliding local blocks into a large containing tensor.\\n\\n\\n\\n\\n\\nPooling layers¶\\n\\n\\nnn.MaxPool1d\\nApplies a 1D max pooling over an input signal composed of several input planes.\\n\\nnn.MaxPool2d\\nApplies a 2D max pooling over an input signal composed of several input planes.\\n\\nnn.MaxPool3d\\nApplies a 3D max pooling over an input signal composed of several input planes.\\n\\nnn.MaxUnpool1d\\nComputes a partial inverse of MaxPool1d.\\n\\nnn.MaxUnpool2d\\nComputes a partial inverse of MaxPool2d.\\n\\nnn.MaxUnpool3d\\nComputes a partial inverse of MaxPool3d.\\n\\nnn.AvgPool1d\\nApplies a 1D average pooling over an input signal composed of several input planes.\\n\\nnn.AvgPool2d\\nApplies a 2D average pooling over an input signal composed of several input planes.\\n\\nnn.AvgPool3d\\nApplies a 3D average pooling over an input signal composed of several input planes.\\n\\nnn.FractionalMaxPool2d\\nApplies a 2D fractional max pooling over an input signal composed of several input planes.\\n\\nnn.FractionalMaxPool3d\\nApplies a 3D fractional max pooling over an input signal composed of several input planes.\\n\\nnn.LPPool1d\\nApplies a 1D power-average pooling over an input signal composed of several input planes.\\n\\nnn.LPPool2d\\nApplies a 2D power-average pooling over an input signal composed of several input planes.\\n\\nnn.LPPool3d\\nApplies a 3D power-average pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveMaxPool1d\\nApplies a 1D adaptive max pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveMaxPool2d\\nApplies a 2D adaptive max pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveMaxPool3d\\nApplies a 3D adaptive max pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveAvgPool1d\\nApplies a 1D adaptive average pooling over an input signal composed of several input planes.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='nn.AdaptiveMaxPool1d\\nApplies a 1D adaptive max pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveMaxPool2d\\nApplies a 2D adaptive max pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveMaxPool3d\\nApplies a 3D adaptive max pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveAvgPool1d\\nApplies a 1D adaptive average pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveAvgPool2d\\nApplies a 2D adaptive average pooling over an input signal composed of several input planes.\\n\\nnn.AdaptiveAvgPool3d\\nApplies a 3D adaptive average pooling over an input signal composed of several input planes.\\n\\n\\n\\n\\n\\nPadding Layers¶\\n\\n\\nnn.ReflectionPad1d\\nPads the input tensor using the reflection of the input boundary.\\n\\nnn.ReflectionPad2d\\nPads the input tensor using the reflection of the input boundary.\\n\\nnn.ReflectionPad3d\\nPads the input tensor using the reflection of the input boundary.\\n\\nnn.ReplicationPad1d\\nPads the input tensor using replication of the input boundary.\\n\\nnn.ReplicationPad2d\\nPads the input tensor using replication of the input boundary.\\n\\nnn.ReplicationPad3d\\nPads the input tensor using replication of the input boundary.\\n\\nnn.ZeroPad1d\\nPads the input tensor boundaries with zero.\\n\\nnn.ZeroPad2d\\nPads the input tensor boundaries with zero.\\n\\nnn.ZeroPad3d\\nPads the input tensor boundaries with zero.\\n\\nnn.ConstantPad1d\\nPads the input tensor boundaries with a constant value.\\n\\nnn.ConstantPad2d\\nPads the input tensor boundaries with a constant value.\\n\\nnn.ConstantPad3d\\nPads the input tensor boundaries with a constant value.\\n\\nnn.CircularPad1d\\nPads the input tensor using circular padding of the input boundary.\\n\\nnn.CircularPad2d\\nPads the input tensor using circular padding of the input boundary.\\n\\nnn.CircularPad3d\\nPads the input tensor using circular padding of the input boundary.\\n\\n\\n\\n\\n\\nNon-linear Activations (weighted sum, nonlinearity)¶\\n\\n\\nnn.ELU\\nApplies the Exponential Linear Unit (ELU) function, element-wise.\\n\\nnn.Hardshrink\\nApplies the Hard Shrinkage (Hardshrink) function element-wise.\\n\\nnn.Hardsigmoid\\nApplies the Hardsigmoid function element-wise.\\n\\nnn.Hardtanh\\nApplies the HardTanh function element-wise.\\n\\nnn.Hardswish\\nApplies the Hardswish function, element-wise.\\n\\nnn.LeakyReLU\\nApplies the LeakyReLU function element-wise.\\n\\nnn.LogSigmoid\\nApplies the Logsigmoid function element-wise.\\n\\nnn.MultiheadAttention\\nAllows the model to jointly attend to information from different representation subspaces.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='nn.Hardshrink\\nApplies the Hard Shrinkage (Hardshrink) function element-wise.\\n\\nnn.Hardsigmoid\\nApplies the Hardsigmoid function element-wise.\\n\\nnn.Hardtanh\\nApplies the HardTanh function element-wise.\\n\\nnn.Hardswish\\nApplies the Hardswish function, element-wise.\\n\\nnn.LeakyReLU\\nApplies the LeakyReLU function element-wise.\\n\\nnn.LogSigmoid\\nApplies the Logsigmoid function element-wise.\\n\\nnn.MultiheadAttention\\nAllows the model to jointly attend to information from different representation subspaces.\\n\\nnn.PReLU\\nApplies the element-wise PReLU function.\\n\\nnn.ReLU\\nApplies the rectified linear unit function element-wise.\\n\\nnn.ReLU6\\nApplies the ReLU6 function element-wise.\\n\\nnn.RReLU\\nApplies the randomized leaky rectified linear unit function, element-wise.\\n\\nnn.SELU\\nApplies the SELU function element-wise.\\n\\nnn.CELU\\nApplies the CELU function element-wise.\\n\\nnn.GELU\\nApplies the Gaussian Error Linear Units function.\\n\\nnn.Sigmoid\\nApplies the Sigmoid function element-wise.\\n\\nnn.SiLU\\nApplies the Sigmoid Linear Unit (SiLU) function, element-wise.\\n\\nnn.Mish\\nApplies the Mish function, element-wise.\\n\\nnn.Softplus\\nApplies the Softplus function element-wise.\\n\\nnn.Softshrink\\nApplies the soft shrinkage function element-wise.\\n\\nnn.Softsign\\nApplies the element-wise Softsign function.\\n\\nnn.Tanh\\nApplies the Hyperbolic Tangent (Tanh) function element-wise.\\n\\nnn.Tanhshrink\\nApplies the element-wise Tanhshrink function.\\n\\nnn.Threshold\\nThresholds each element of the input Tensor.\\n\\nnn.GLU\\nApplies the gated linear unit function.\\n\\n\\n\\n\\n\\nNon-linear Activations (other)¶\\n\\n\\nnn.Softmin\\nApplies the Softmin function to an n-dimensional input Tensor.\\n\\nnn.Softmax\\nApplies the Softmax function to an n-dimensional input Tensor.\\n\\nnn.Softmax2d\\nApplies SoftMax over features to each spatial location.\\n\\nnn.LogSoftmax\\nApplies the log\\u2061(Softmax(x))\\\\log(\\\\text{Softmax}(x))log(Softmax(x)) function to an n-dimensional input Tensor.\\n\\nnn.AdaptiveLogSoftmaxWithLoss\\nEfficient softmax approximation.\\n\\n\\n\\n\\n\\nNormalization Layers¶\\n\\n\\nnn.BatchNorm1d\\nApplies Batch Normalization over a 2D or 3D input.\\n\\nnn.BatchNorm2d\\nApplies Batch Normalization over a 4D input.\\n\\nnn.BatchNorm3d\\nApplies Batch Normalization over a 5D input.\\n\\nnn.LazyBatchNorm1d\\nA torch.nn.BatchNorm1d module with lazy initialization.\\n\\nnn.LazyBatchNorm2d\\nA torch.nn.BatchNorm2d module with lazy initialization.\\n\\nnn.LazyBatchNorm3d\\nA torch.nn.BatchNorm3d module with lazy initialization.\\n\\nnn.GroupNorm\\nApplies Group Normalization over a mini-batch of inputs.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='nn.BatchNorm1d\\nApplies Batch Normalization over a 2D or 3D input.\\n\\nnn.BatchNorm2d\\nApplies Batch Normalization over a 4D input.\\n\\nnn.BatchNorm3d\\nApplies Batch Normalization over a 5D input.\\n\\nnn.LazyBatchNorm1d\\nA torch.nn.BatchNorm1d module with lazy initialization.\\n\\nnn.LazyBatchNorm2d\\nA torch.nn.BatchNorm2d module with lazy initialization.\\n\\nnn.LazyBatchNorm3d\\nA torch.nn.BatchNorm3d module with lazy initialization.\\n\\nnn.GroupNorm\\nApplies Group Normalization over a mini-batch of inputs.\\n\\nnn.SyncBatchNorm\\nApplies Batch Normalization over a N-Dimensional input.\\n\\nnn.InstanceNorm1d\\nApplies Instance Normalization.\\n\\nnn.InstanceNorm2d\\nApplies Instance Normalization.\\n\\nnn.InstanceNorm3d\\nApplies Instance Normalization.\\n\\nnn.LazyInstanceNorm1d\\nA torch.nn.InstanceNorm1d module with lazy initialization of the num_features argument.\\n\\nnn.LazyInstanceNorm2d\\nA torch.nn.InstanceNorm2d module with lazy initialization of the num_features argument.\\n\\nnn.LazyInstanceNorm3d\\nA torch.nn.InstanceNorm3d module with lazy initialization of the num_features argument.\\n\\nnn.LayerNorm\\nApplies Layer Normalization over a mini-batch of inputs.\\n\\nnn.LocalResponseNorm\\nApplies local response normalization over an input signal.\\n\\nnn.RMSNorm\\nApplies Root Mean Square Layer Normalization over a mini-batch of inputs.\\n\\n\\n\\n\\n\\nRecurrent Layers¶\\n\\n\\nnn.RNNBase\\nBase class for RNN modules (RNN, LSTM, GRU).\\n\\nnn.RNN\\nApply a multi-layer Elman RNN with tanh\\u2061\\\\tanhtanh or ReLU\\\\text{ReLU}ReLU non-linearity to an input sequence.\\n\\nnn.LSTM\\nApply a multi-layer long short-term memory (LSTM) RNN to an input sequence.\\n\\nnn.GRU\\nApply a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\\n\\nnn.RNNCell\\nAn Elman RNN cell with tanh or ReLU non-linearity.\\n\\nnn.LSTMCell\\nA long short-term memory (LSTM) cell.\\n\\nnn.GRUCell\\nA gated recurrent unit (GRU) cell.\\n\\n\\n\\n\\n\\nTransformer Layers¶\\n\\n\\nnn.Transformer\\nA transformer model.\\n\\nnn.TransformerEncoder\\nTransformerEncoder is a stack of N encoder layers.\\n\\nnn.TransformerDecoder\\nTransformerDecoder is a stack of N decoder layers.\\n\\nnn.TransformerEncoderLayer\\nTransformerEncoderLayer is made up of self-attn and feedforward network.\\n\\nnn.TransformerDecoderLayer\\nTransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\\n\\n\\n\\n\\n\\nLinear Layers¶\\n\\n\\nnn.Identity\\nA placeholder identity operator that is argument-insensitive.\\n\\nnn.Linear\\nApplies an affine linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content=\"nn.TransformerDecoder\\nTransformerDecoder is a stack of N decoder layers.\\n\\nnn.TransformerEncoderLayer\\nTransformerEncoderLayer is made up of self-attn and feedforward network.\\n\\nnn.TransformerDecoderLayer\\nTransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\\n\\n\\n\\n\\n\\nLinear Layers¶\\n\\n\\nnn.Identity\\nA placeholder identity operator that is argument-insensitive.\\n\\nnn.Linear\\nApplies an affine linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b.\\n\\nnn.Bilinear\\nApplies a bilinear transformation to the incoming data: y=x1TAx2+by = x_1^T A x_2 + by=x1T\\u200bAx2\\u200b+b.\\n\\nnn.LazyLinear\\nA torch.nn.Linear module where in_features is inferred.\\n\\n\\n\\n\\n\\nDropout Layers¶\\n\\n\\nnn.Dropout\\nDuring training, randomly zeroes some of the elements of the input tensor with probability p.\\n\\nnn.Dropout1d\\nRandomly zero out entire channels.\\n\\nnn.Dropout2d\\nRandomly zero out entire channels.\\n\\nnn.Dropout3d\\nRandomly zero out entire channels.\\n\\nnn.AlphaDropout\\nApplies Alpha Dropout over the input.\\n\\nnn.FeatureAlphaDropout\\nRandomly masks out entire channels.\\n\\n\\n\\n\\n\\nSparse Layers¶\\n\\n\\nnn.Embedding\\nA simple lookup table that stores embeddings of a fixed dictionary and size.\\n\\nnn.EmbeddingBag\\nCompute sums or means of 'bags' of embeddings, without instantiating the intermediate embeddings.\\n\\n\\n\\n\\n\\nDistance Functions¶\\n\\n\\nnn.CosineSimilarity\\nReturns cosine similarity between x1x_1x1\\u200b and x2x_2x2\\u200b, computed along dim.\\n\\nnn.PairwiseDistance\\nComputes the pairwise distance between input vectors, or between columns of input matrices.\\n\\n\\n\\n\\n\\nLoss Functions¶\\n\\n\\nnn.L1Loss\\nCreates a criterion that measures the mean absolute error (MAE) between each element in the input xxx and target yyy.\\n\\nnn.MSELoss\\nCreates a criterion that measures the mean squared error (squared L2 norm) between each element in the input xxx and target yyy.\\n\\nnn.CrossEntropyLoss\\nThis criterion computes the cross entropy loss between input logits and target.\\n\\nnn.CTCLoss\\nThe Connectionist Temporal Classification loss.\\n\\nnn.NLLLoss\\nThe negative log likelihood loss.\\n\\nnn.PoissonNLLLoss\\nNegative log likelihood loss with Poisson distribution of target.\\n\\nnn.GaussianNLLLoss\\nGaussian negative log likelihood loss.\\n\\nnn.KLDivLoss\\nThe Kullback-Leibler divergence loss.\\n\\nnn.BCELoss\\nCreates a criterion that measures the Binary Cross Entropy between the target and the input probabilities:\\n\\nnn.BCEWithLogitsLoss\\nThis loss combines a Sigmoid layer and the BCELoss in one single class.\"),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='nn.NLLLoss\\nThe negative log likelihood loss.\\n\\nnn.PoissonNLLLoss\\nNegative log likelihood loss with Poisson distribution of target.\\n\\nnn.GaussianNLLLoss\\nGaussian negative log likelihood loss.\\n\\nnn.KLDivLoss\\nThe Kullback-Leibler divergence loss.\\n\\nnn.BCELoss\\nCreates a criterion that measures the Binary Cross Entropy between the target and the input probabilities:\\n\\nnn.BCEWithLogitsLoss\\nThis loss combines a Sigmoid layer and the BCELoss in one single class.\\n\\nnn.MarginRankingLoss\\nCreates a criterion that measures the loss given inputs x1x1x1, x2x2x2, two 1D mini-batch or 0D Tensors, and a label 1D mini-batch or 0D Tensor yyy (containing 1 or -1).\\n\\nnn.HingeEmbeddingLoss\\nMeasures the loss given an input tensor xxx and a labels tensor yyy (containing 1 or -1).\\n\\nnn.MultiLabelMarginLoss\\nCreates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input xxx (a 2D mini-batch Tensor) and output yyy (which is a 2D Tensor of target class indices).\\n\\nnn.HuberLoss\\nCreates a criterion that uses a squared term if the absolute element-wise error falls below delta and a delta-scaled L1 term otherwise.\\n\\nnn.SmoothL1Loss\\nCreates a criterion that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise.\\n\\nnn.SoftMarginLoss\\nCreates a criterion that optimizes a two-class classification logistic loss between input tensor xxx and target tensor yyy (containing 1 or -1).\\n\\nnn.MultiLabelSoftMarginLoss\\nCreates a criterion that optimizes a multi-label one-versus-all loss based on max-entropy, between input xxx and target yyy of size (N,C)(N, C)(N,C).\\n\\nnn.CosineEmbeddingLoss\\nCreates a criterion that measures the loss given input tensors x1x_1x1\\u200b, x2x_2x2\\u200b and a Tensor label yyy with values 1 or -1.\\n\\nnn.MultiMarginLoss\\nCreates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input xxx (a 2D mini-batch Tensor) and output yyy (which is a 1D tensor of target class indices, 0≤y≤x.size(1)−10 \\\\leq y \\\\leq \\\\text{x.size}(1)-10≤y≤x.size(1)−1):\\n\\nnn.TripletMarginLoss\\nCreates a criterion that measures the triplet loss given an input tensors x1x1x1, x2x2x2, x3x3x3 and a margin with a value greater than 000.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='nn.MultiMarginLoss\\nCreates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input xxx (a 2D mini-batch Tensor) and output yyy (which is a 1D tensor of target class indices, 0≤y≤x.size(1)−10 \\\\leq y \\\\leq \\\\text{x.size}(1)-10≤y≤x.size(1)−1):\\n\\nnn.TripletMarginLoss\\nCreates a criterion that measures the triplet loss given an input tensors x1x1x1, x2x2x2, x3x3x3 and a margin with a value greater than 000.\\n\\nnn.TripletMarginWithDistanceLoss\\nCreates a criterion that measures the triplet loss given input tensors aaa, ppp, and nnn (representing anchor, positive, and negative examples, respectively), and a nonnegative, real-valued function (\"distance function\") used to compute the relationship between the anchor and positive example (\"positive distance\") and the anchor and negative example (\"negative distance\").\\n\\n\\n\\n\\n\\nVision Layers¶\\n\\n\\nnn.PixelShuffle\\nRearrange elements in a tensor according to an upscaling factor.\\n\\nnn.PixelUnshuffle\\nReverse the PixelShuffle operation.\\n\\nnn.Upsample\\nUpsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.\\n\\nnn.UpsamplingNearest2d\\nApplies a 2D nearest neighbor upsampling to an input signal composed of several input channels.\\n\\nnn.UpsamplingBilinear2d\\nApplies a 2D bilinear upsampling to an input signal composed of several input channels.\\n\\n\\n\\n\\n\\nShuffle Layers¶\\n\\n\\nnn.ChannelShuffle\\nDivides and rearranges the channels in a tensor.\\n\\n\\n\\n\\n\\nDataParallel Layers (multi-GPU, distributed)¶\\n\\n\\nnn.DataParallel\\nImplements data parallelism at the module level.\\n\\nnn.parallel.DistributedDataParallel\\nImplement distributed data parallelism based on torch.distributed at module level.\\n\\n\\n\\n\\n\\nUtilities¶\\nFrom the torch.nn.utils module:\\nUtility functions to clip parameter gradients.\\n\\n\\nclip_grad_norm_\\nClip the gradient norm of an iterable of parameters.\\n\\nclip_grad_norm\\nClip the gradient norm of an iterable of parameters.\\n\\nclip_grad_value_\\nClip the gradients of an iterable of parameters at specified value.\\n\\nget_total_norm\\nCompute the norm of an iterable of tensors.\\n\\nclip_grads_with_norm_\\nScale the gradients of an iterable of parameters given a pre-calculated total norm and desired max norm.\\n\\n\\n\\nUtility functions to flatten and unflatten Module parameters to and from a single vector.\\n\\n\\nparameters_to_vector\\nFlatten an iterable of parameters into a single vector.\\n\\nvector_to_parameters\\nCopy slices of a vector into an iterable of parameters.\\n\\n\\n\\nUtility functions to fuse Modules with BatchNorm modules.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='get_total_norm\\nCompute the norm of an iterable of tensors.\\n\\nclip_grads_with_norm_\\nScale the gradients of an iterable of parameters given a pre-calculated total norm and desired max norm.\\n\\n\\n\\nUtility functions to flatten and unflatten Module parameters to and from a single vector.\\n\\n\\nparameters_to_vector\\nFlatten an iterable of parameters into a single vector.\\n\\nvector_to_parameters\\nCopy slices of a vector into an iterable of parameters.\\n\\n\\n\\nUtility functions to fuse Modules with BatchNorm modules.\\n\\n\\nfuse_conv_bn_eval\\nFuse a convolutional module and a BatchNorm module into a single, new convolutional module.\\n\\nfuse_conv_bn_weights\\nFuse convolutional module parameters and BatchNorm module parameters into new convolutional module parameters.\\n\\nfuse_linear_bn_eval\\nFuse a linear module and a BatchNorm module into a single, new linear module.\\n\\nfuse_linear_bn_weights\\nFuse linear module parameters and BatchNorm module parameters into new linear module parameters.\\n\\n\\n\\nUtility functions to convert Module parameter memory formats.\\n\\n\\nconvert_conv2d_weight_memory_format\\nConvert memory_format of nn.Conv2d.weight to memory_format.\\n\\nconvert_conv3d_weight_memory_format\\nConvert memory_format of nn.Conv3d.weight to memory_format The conversion recursively applies to nested nn.Module, including module.\\n\\n\\n\\nUtility functions to apply and remove weight normalization from Module parameters.\\n\\n\\nweight_norm\\nApply weight normalization to a parameter in the given module.\\n\\nremove_weight_norm\\nRemove the weight normalization reparameterization from a module.\\n\\nspectral_norm\\nApply spectral normalization to a parameter in the given module.\\n\\nremove_spectral_norm\\nRemove the spectral normalization reparameterization from a module.\\n\\n\\n\\nUtility functions for initializing Module parameters.\\n\\n\\nskip_init\\nGiven a module class object and args / kwargs, instantiate the module without initializing parameters / buffers.\\n\\n\\n\\nUtility classes and functions for pruning Module parameters.\\n\\n\\nprune.BasePruningMethod\\nAbstract base class for creation of new pruning techniques.\\n\\nprune.PruningContainer\\nContainer holding a sequence of pruning methods for iterative pruning.\\n\\nprune.Identity\\nUtility pruning method that does not prune any units but generates the pruning parametrization with a mask of ones.\\n\\nprune.RandomUnstructured\\nPrune (currently unpruned) units in a tensor at random.\\n\\nprune.L1Unstructured\\nPrune (currently unpruned) units in a tensor by zeroing out the ones with the lowest L1-norm.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='prune.PruningContainer\\nContainer holding a sequence of pruning methods for iterative pruning.\\n\\nprune.Identity\\nUtility pruning method that does not prune any units but generates the pruning parametrization with a mask of ones.\\n\\nprune.RandomUnstructured\\nPrune (currently unpruned) units in a tensor at random.\\n\\nprune.L1Unstructured\\nPrune (currently unpruned) units in a tensor by zeroing out the ones with the lowest L1-norm.\\n\\nprune.RandomStructured\\nPrune entire (currently unpruned) channels in a tensor at random.\\n\\nprune.LnStructured\\nPrune entire (currently unpruned) channels in a tensor based on their Ln-norm.\\n\\nprune.CustomFromMask\\n\\n\\nprune.identity\\nApply pruning reparametrization without pruning any units.\\n\\nprune.random_unstructured\\nPrune tensor by removing random (currently unpruned) units.\\n\\nprune.l1_unstructured\\nPrune tensor by removing units with the lowest L1-norm.\\n\\nprune.random_structured\\nPrune tensor by removing random channels along the specified dimension.\\n\\nprune.ln_structured\\nPrune tensor by removing channels with the lowest Ln-norm along the specified dimension.\\n\\nprune.global_unstructured\\nGlobally prunes tensors corresponding to all parameters in parameters by applying the specified pruning_method.\\n\\nprune.custom_from_mask\\nPrune tensor corresponding to parameter called name in module by applying the pre-computed mask in mask.\\n\\nprune.remove\\nRemove the pruning reparameterization from a module and the pruning method from the forward hook.\\n\\nprune.is_pruned\\nCheck if a module is pruned by looking for pruning pre-hooks.\\n\\n\\n\\nParametrizations implemented using the new parametrization functionality\\nin torch.nn.utils.parameterize.register_parametrization().\\n\\n\\nparametrizations.orthogonal\\nApply an orthogonal or unitary parametrization to a matrix or a batch of matrices.\\n\\nparametrizations.weight_norm\\nApply weight normalization to a parameter in the given module.\\n\\nparametrizations.spectral_norm\\nApply spectral normalization to a parameter in the given module.\\n\\n\\n\\nUtility functions to parametrize Tensors on existing Modules.\\nNote that these functions can be used to parametrize a given Parameter\\nor Buffer given a specific function that maps from an input space to the\\nparametrized space. They are not parameterizations that would transform\\nan object into a parameter. See the\\nParametrizations tutorial\\nfor more information on how to implement your own parametrizations.\\n\\n\\nparametrize.register_parametrization\\nRegister a parametrization to a tensor in a module.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='Utility functions to parametrize Tensors on existing Modules.\\nNote that these functions can be used to parametrize a given Parameter\\nor Buffer given a specific function that maps from an input space to the\\nparametrized space. They are not parameterizations that would transform\\nan object into a parameter. See the\\nParametrizations tutorial\\nfor more information on how to implement your own parametrizations.\\n\\n\\nparametrize.register_parametrization\\nRegister a parametrization to a tensor in a module.\\n\\nparametrize.remove_parametrizations\\nRemove the parametrizations on a tensor in a module.\\n\\nparametrize.cached\\nContext manager that enables the caching system within parametrizations registered with register_parametrization().\\n\\nparametrize.is_parametrized\\nDetermine if a module has a parametrization.\\n\\n\\n\\n\\n\\nparametrize.ParametrizationList\\nA sequential container that holds and manages the original parameters or buffers of a parametrized torch.nn.Module.\\n\\n\\n\\nUtility functions to call a given Module in a stateless manner.\\n\\n\\nstateless.functional_call\\nPerform a functional call on the module by replacing the module parameters and buffers with the provided ones.\\n\\n\\n\\nUtility functions in other modules\\n\\n\\nnn.utils.rnn.PackedSequence\\nHolds the data and list of batch_sizes of a packed sequence.\\n\\nnn.utils.rnn.pack_padded_sequence\\nPacks a Tensor containing padded sequences of variable length.\\n\\nnn.utils.rnn.pad_packed_sequence\\nPad a packed batch of variable length sequences.\\n\\nnn.utils.rnn.pad_sequence\\nPad a list of variable length Tensors with padding_value.\\n\\nnn.utils.rnn.pack_sequence\\nPacks a list of variable length Tensors.\\n\\nnn.utils.rnn.unpack_sequence\\nUnpack PackedSequence into a list of variable length Tensors.\\n\\nnn.utils.rnn.unpad_sequence\\nUnpad padded Tensor into a list of variable length Tensors.\\n\\n\\n\\n\\n\\nnn.Flatten\\nFlattens a contiguous range of dims into a tensor.\\n\\nnn.Unflatten\\nUnflattens a tensor dim expanding it to a desired shape.\\n\\n\\n\\n\\n\\nQuantized Functions¶\\nQuantization refers to techniques for performing computations and storing tensors at lower bitwidths than\\nfloating point precision. PyTorch supports both per tensor and per channel asymmetric linear quantization. To learn more how to use quantized functions in PyTorch, please refer to the Quantization documentation.\\n\\n\\nLazy Modules Initialization¶\\n\\n\\nnn.modules.lazy.LazyModuleMixin\\nA mixin for modules that lazily initialize parameters, also known as \"lazy modules\".'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='Quantized Functions¶\\nQuantization refers to techniques for performing computations and storing tensors at lower bitwidths than\\nfloating point precision. PyTorch supports both per tensor and per channel asymmetric linear quantization. To learn more how to use quantized functions in PyTorch, please refer to the Quantization documentation.\\n\\n\\nLazy Modules Initialization¶\\n\\n\\nnn.modules.lazy.LazyModuleMixin\\nA mixin for modules that lazily initialize parameters, also known as \"lazy modules\".\\n\\n\\n\\n\\nAliases¶\\nThe following are aliases to their counterparts in torch.nn:\\n\\n\\nnn.modules.normalization.RMSNorm\\nApplies Root Mean Square Layer Normalization over a mini-batch of inputs.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNext \\n Previous\\n\\n\\n\\n\\n        © Copyright 2024, PyTorch Contributors.\\n\\n    \\n\\n\\n        Built with Sphinx using a theme provided by Read the Docs.\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\ntorch.nn\\nContainers\\n\\n\\nConvolution Layers\\nPooling layers\\nPadding Layers\\nNon-linear Activations (weighted sum, nonlinearity)\\nNon-linear Activations (other)\\nNormalization Layers\\nRecurrent Layers\\nTransformer Layers\\nLinear Layers\\nDropout Layers\\nSparse Layers\\nDistance Functions\\nLoss Functions\\nVision Layers\\nShuffle Layers\\nDataParallel Layers (multi-GPU, distributed)\\nUtilities\\n\\n\\nQuantized Functions\\nLazy Modules Initialization\\nAliases\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDocs\\nAccess comprehensive developer documentation for PyTorch\\nView Docs\\n\\n\\nTutorials\\nGet in-depth tutorials for beginners and advanced developers\\nView Tutorials\\n\\n\\nResources\\nFind development resources and get your questions answered\\nView Resources\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPyTorch\\nGet Started\\nFeatures\\nEcosystem\\nBlog\\nContributing\\n\\n\\n\\n\\nResources\\nTutorials\\nDocs\\nDiscuss\\nGithub Issues\\nBrand Guidelines\\n\\n\\n\\n\\nStay up to date\\nFacebook\\nTwitter\\nYouTube\\nLinkedIn\\n\\n\\n\\n\\nPyTorch Podcasts\\nSpotify\\nApple\\nGoogle\\nAmazon\\n\\n\\n\\n\\n\\nTerms\\n|\\nPrivacy\\n\\n\\n\\n© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.\\n          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see\\n          www.linuxfoundation.org/policies/. The PyTorch Foundation supports the PyTorch open source\\n          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,\\n          please see www.lfprojects.org/policies/.'),\n",
       " Document(metadata={'source': 'https://pytorch.org/docs/stable/nn.html', 'title': 'torch.nn — PyTorch 2.6 documentation', 'language': 'en'}, page_content='To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: Cookies Policy.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLearn\\n\\n\\n\\nGet Started\\n\\n\\nTutorials\\n\\n\\nLearn the Basics\\n\\n\\nPyTorch Recipes\\n\\n\\nIntroduction to PyTorch - YouTube Series\\n\\n\\n\\nEcosystem\\n\\n\\n\\nTools\\n\\n\\nCommunity\\n\\n\\nForums\\n\\n\\nDeveloper Resources\\n\\n\\nContributor Awards - 2023\\n\\n\\n\\nEdge\\n\\n\\n\\nAbout PyTorch Edge\\n\\n\\nExecuTorch\\n\\n\\n\\nDocs\\n\\n\\n\\nPyTorch\\n\\n\\nPyTorch Domains\\n\\n\\n\\nBlog & News\\n\\n\\n\\nPyTorch Blog\\n\\n\\nCommunity Blog\\n\\n\\nVideos\\n\\n\\nCommunity Stories\\n\\n\\nEvents\\n\\n\\n\\nAbout\\n\\n\\n\\nPyTorch Foundation\\n\\n\\nGoverning Board')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_docs = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=500).split_documents(documents)\n",
    "text_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1180cb7d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = FAISS.from_documents(text_docs, OpenAIEmbeddings())\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1180cb7d0>, search_kwargs={})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Containers'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever, 'Containers', 'Search what are Containers in pytorch and what are the types')\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model='Llama-3.3-70b-Versatile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x108216de0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x108216de0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x11d2515e0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x11d252780>, model_name='Llama-3.3-70b-Versatile', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'Containers', 'description': 'Search what are Containers in pytorch and what are the types', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import  AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(tools=tools, agent=agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1706.03762'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks in an encoder-decoder configuration. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer, base\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Transformer (machine learning) model'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Transformer (deep learning architecture)\n",
      "Summary: The transformer is a deep learning architecture that was developed by researchers at Google and is based on the multi-head attention mechanism, which was proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window wi\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Attention Is All You Need'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2024-07-22\n",
      "Title: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\n",
      "Authors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\n",
      "Summary: The inference demand for LLMs has skyrocketed in recent months, and serving\n",
      "models with low latencies remains challenging due to the quadratic input length\n",
      "complexity of the attention layers. In this work, we investigate the effect of\n",
      "dropping MLP and attention layers at inference time o\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Transformer (machine learning) model applications'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2018-10-19\n",
      "Title: Learning Multi-Layer Transform Models\n",
      "Authors: Saiprasad Ravishankar, Brendt Wohlberg\n",
      "Summary: Learned data models based on sparsity are widely used in signal processing\n",
      "and imaging applications. A variety of methods for learning synthesis\n",
      "dictionaries, sparsifying transforms, etc., have been proposed in recent years,\n",
      "often imposing useful structures or properties on the models. In this work, we\n",
      "focus on sparsifying transform learning, which enjoys a number of advant\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Containers` with `{'query': 'PyTorch container types'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLanguage Bindings\n",
      "\n",
      "C++\n",
      "Javadoc\n",
      "torch::deploy\n",
      "\n",
      "Python API\n",
      "\n",
      "torch\n",
      "torch.nn\n",
      "torch.nn.functional\n",
      "torch.Tensor\n",
      "Tensor Attributes\n",
      "Tensor Views\n",
      "torch.amp\n",
      "torch.autograd\n",
      "torch.library\n",
      "torch.accelerator\n",
      "torch.cpu\n",
      "torch.cuda\n",
      "Understanding CUDA Memory Usage\n",
      "Generating a Snapshot\n",
      "Using the visualizer\n",
      "Snapshot API Reference\n",
      "torch.mps\n",
      "torch.xpu\n",
      "torch.mtia\n",
      "torch.mtia.memory\n",
      "Meta device\n",
      "torch.backends\n",
      "torch.export\n",
      "torch.distributed\n",
      "torch.distributed.tensor\n",
      "torch.distributed.algorithms.join\n",
      "torch.distributed.elastic\n",
      "torch.distributed.fsdp\n",
      "torch.distributed.fsdp.fully_shard\n",
      "torch.distributed.tensor.parallel\n",
      "torch.distributed.optim\n",
      "torch.distributed.pipelining\n",
      "torch.distributed.checkpoint\n",
      "torch.distributions\n",
      "torch.compiler\n",
      "torch.fft\n",
      "torch.func\n",
      "torch.futures\n",
      "torch.fx\n",
      "torch.fx.experimental\n",
      "torch.hub\n",
      "torch.jit\n",
      "torch.linalg\n",
      "torch.monitor\n",
      "torch.signal\n",
      "torch.special\n",
      "torch.overrides\n",
      "torch.package\n",
      "torch.profiler\n",
      "torch.nn.init\n",
      "torch.nn.attention\n",
      "torch.onnx\n",
      "torch.optim\n",
      "Complex Numbers\n",
      "DDP Communication Hooks\n",
      "Quantization\n",
      "Distributed RPC Framework\n",
      "torch.random\n",
      "torch.masked\n",
      "torch.nested\n",
      "torch.Size\n",
      "torch.sparse\n",
      "torch.Storage\n",
      "torch.testing\n",
      "torch.utils\n",
      "torch.utils.benchmark\n",
      "torch.utils.bottleneck\n",
      "torch.utils.checkpoint\n",
      "torch.utils.cpp_extension\n",
      "torch.utils.data\n",
      "torch.utils.deterministic\n",
      "torch.utils.jit\n",
      "torch.utils.dlpack\n",
      "torch.utils.mobile_optimizer\n",
      "torch.utils.model_zoo\n",
      "torch.utils.tensorboard\n",
      "torch.utils.module_tracker\n",
      "Type Info\n",
      "Named Tensors\n",
      "Named Tensors operator coverage\n",
      "torch.__config__\n",
      "torch.__future__\n",
      "torch._logging\n",
      "Torch Environment Variables\n",
      "\n",
      "Libraries\n",
      "\n",
      "torchaudio\n",
      "TorchData\n",
      "TorchRec\n",
      "TorchServe\n",
      "torchtext\n",
      "torchvision\n",
      "PyTorch on XLA Devices\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "            Docs\n",
      "          \n",
      "         >\n",
      "      \n",
      "torch.nn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Shortcuts\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torch.nn¶\n",
      "These are the basic building blocks for graphs:\n",
      "\n",
      "torch.nn\n",
      "\n",
      "Containers\n",
      "Convolution Layers\n",
      "Pooling layers\n",
      "Padding Layers\n",
      "Non-linear Activations (weighted sum, nonlinearity)\n",
      "Non-linear Activations (other)\n",
      "Normalization Layers\n",
      "Recurrent Layers\n",
      "Transformer Layers\n",
      "Linear Layers\n",
      "Dropout Layers\n",
      "Sparse Layers\n",
      "Distance Functions\n",
      "Loss Functions\n",
      "Vision Layers\n",
      "Shuffle Layers\n",
      "DataParallel Layers (multi-GPU, distributed)\n",
      "Utilities\n",
      "Quantized Functions\n",
      "Lazy Modules Initialization\n",
      "\n",
      "Aliases\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Buffer\n",
      "A kind of Tensor that should not be considered a model parameter.\n",
      "\n",
      "Parameter\n",
      "A kind of Tensor that is to be considered a module parameter.\n",
      "\n",
      "UninitializedParameter\n",
      "A parameter that is not initialized.\n",
      "\n",
      "torch.nn — PyTorch 2.6 documentation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Learn\n",
      "              \n",
      "\n",
      "\n",
      "Get Started\n",
      "Run PyTorch locally or get started quickly with one of the supported cloud platforms\n",
      "\n",
      "\n",
      "Tutorials\n",
      "Whats new in PyTorch tutorials\n",
      "\n",
      "\n",
      "Learn the Basics\n",
      "Familiarize yourself with PyTorch concepts and modules\n",
      "\n",
      "\n",
      "PyTorch Recipes\n",
      "Bite-size, ready-to-deploy PyTorch code examples\n",
      "\n",
      "\n",
      "Intro to PyTorch - YouTube Series\n",
      "Master PyTorch basics with our engaging YouTube tutorial series\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Ecosystem\n",
      "              \n",
      "\n",
      "\n",
      "Tools\n",
      "Learn about the tools and frameworks in the PyTorch Ecosystem\n",
      "\n",
      "\n",
      "Community\n",
      "Join the PyTorch developer community to contribute, learn, and get your questions answered\n",
      "\n",
      "\n",
      "Forums\n",
      "A place to discuss PyTorch code, issues, install, research\n",
      "\n",
      "\n",
      "Developer Resources\n",
      "Find resources and get questions answered\n",
      "\n",
      "\n",
      "Contributor Awards - 2023\n",
      "Award winners announced at this year's PyTorch Conference\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Edge\n",
      "              \n",
      "\n",
      "\n",
      "About PyTorch Edge\n",
      "Build innovative and privacy-aware AI experiences for edge devices\n",
      "\n",
      "\n",
      "ExecuTorch\n",
      "End-to-end solution for enabling on-device inference capabilities across mobile and edge devices\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Docs\n",
      "              \n",
      "\n",
      "\n",
      "PyTorch\n",
      "Explore the documentation for comprehensive guidance on how to use PyTorch\n",
      "\n",
      "\n",
      "PyTorch Domains\n",
      "Read the PyTorch Domains documentation to learn more about domain-specific libraries\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Blogs & News \n",
      "              \n",
      "\n",
      "\n",
      "PyTorch Blog\n",
      "Catch up on the latest technical news and happenings\n",
      "\n",
      "\n",
      "Community Blog\n",
      "Stories from the PyTorch ecosystem\n",
      "\n",
      "\n",
      "Videos\n",
      "Learn about the latest PyTorch tutorials, new, and more \n",
      "\n",
      "Community Stories\n",
      "Learn how our community solves real, everyday machine learning problems with PyTorch\n",
      "\n",
      "\n",
      "Events\n",
      "Find events, webinars, and podcasts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                About\n",
      "              \n",
      "\n",
      "\n",
      "PyTorch Foundation\n",
      "Learn more about the PyTorch Foundation\n",
      "\n",
      "\n",
      "Governing Board\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Become a Member\n",
      "              \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2.6 ▼\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Google Search\n",
      "    \n",
      "\n",
      "\n",
      "      Classic Search\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Share Your Feedback about our new search\n",
      "\n",
      "\n",
      "Community\n",
      "\n",
      "PyTorch Governance | Build + CI\n",
      "PyTorch Contribution Guide\n",
      "PyTorch Design Philosophy\n",
      "PyTorch Governance | Mechanics\n",
      "PyTorch Governance | Maintainers\n",
      "\n",
      "Developer Notes\n",
      "\n",
      "PyTorch Foundation\n",
      "Learn more about the PyTorch Foundation\n",
      "\n",
      "\n",
      "Governing Board\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Become a Member\n",
      "              \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2.6 ▼\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Google Search\n",
      "    \n",
      "\n",
      "\n",
      "      Classic Search\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Share Your Feedback about our new search\n",
      "\n",
      "\n",
      "Community\n",
      "\n",
      "PyTorch Governance | Build + CI\n",
      "PyTorch Contribution Guide\n",
      "PyTorch Design Philosophy\n",
      "PyTorch Governance | Mechanics\n",
      "PyTorch Governance | Maintainers\n",
      "\n",
      "Developer Notes\n",
      "\n",
      "Automatic Mixed Precision examples\n",
      "Autograd mechanics\n",
      "Broadcasting semantics\n",
      "CPU threading and TorchScript inference\n",
      "CUDA semantics\n",
      "PyTorch Custom Operators Landing Page\n",
      "Distributed Data Parallel\n",
      "Extending PyTorch\n",
      "Extending torch.func with autograd.Function\n",
      "Frequently Asked Questions\n",
      "FSDP Notes\n",
      "Getting Started on Intel GPU\n",
      "Gradcheck mechanics\n",
      "HIP (ROCm) semantics\n",
      "Features for large-scale deployments\n",
      "Modules\n",
      "MPS backend\n",
      "Multiprocessing best practices\n",
      "Numerical accuracy\n",
      "Reproducibility\n",
      "Serialization semantics\n",
      "Windows FAQ\n",
      "\n",
      "Language Bindings\n",
      "\n",
      "C++\n",
      "Javadoc\n",
      "torch::deploy\n",
      "\n",
      "Python API\n",
      "\n",
      "To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: Cookies Policy.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learn\n",
      "\n",
      "\n",
      "\n",
      "Get Started\n",
      "\n",
      "\n",
      "Tutorials\n",
      "\n",
      "\n",
      "Learn the Basics\n",
      "\n",
      "\n",
      "PyTorch Recipes\n",
      "\n",
      "\n",
      "Introduction to PyTorch - YouTube Series\n",
      "\n",
      "\n",
      "\n",
      "Ecosystem\n",
      "\n",
      "\n",
      "\n",
      "Tools\n",
      "\n",
      "\n",
      "Community\n",
      "\n",
      "\n",
      "Forums\n",
      "\n",
      "\n",
      "Developer Resources\n",
      "\n",
      "\n",
      "Contributor Awards - 2023\n",
      "\n",
      "\n",
      "\n",
      "Edge\n",
      "\n",
      "\n",
      "\n",
      "About PyTorch Edge\n",
      "\n",
      "\n",
      "ExecuTorch\n",
      "\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "PyTorch\n",
      "\n",
      "\n",
      "PyTorch Domains\n",
      "\n",
      "\n",
      "\n",
      "Blog & News\n",
      "\n",
      "\n",
      "\n",
      "PyTorch Blog\n",
      "\n",
      "\n",
      "Community Blog\n",
      "\n",
      "\n",
      "Videos\n",
      "\n",
      "\n",
      "Community Stories\n",
      "\n",
      "\n",
      "Events\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "\n",
      "\n",
      "\n",
      "PyTorch Foundation\n",
      "\n",
      "\n",
      "Governing Board\u001b[0m"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/groq/_base_client.py:1040\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_models.py:763\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 763\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1706.03762\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain/agents/agent.py:1624\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1624\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1633\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1634\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain/agents/agent.py:1332\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1323\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m   1330\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m-> 1332\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1340\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain/agents/agent.py:1358\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1357\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1358\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain/agents/agent.py:581\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 581\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:3409\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   3404\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3405\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   3406\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3407\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3409\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:3396\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   3391\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3392\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   3393\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3394\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3395\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3396\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   3397\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   3399\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   3400\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3401\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:2196\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2195\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 2196\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   2198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:3359\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3357\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[0;32m-> 3359\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:1414\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m final: Input\n\u001b[1;32m   1412\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1414\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[1;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[1;32m   1417\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[1;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[1;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[1;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:5567\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   5562\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5563\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   5564\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5565\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   5566\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 5567\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   5568\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5569\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5570\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5571\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:1432\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:415\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiter\u001b[38;5;241m.\u001b[39macquire(blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_groq/chat_models.py:516\u001b[0m, in \u001b[0;36mChatGroq._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m    515\u001b[0m default_chunk_class: Type[BaseMessageChunk] \u001b[38;5;241m=\u001b[39m AIMessageChunk\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    518\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/groq/resources/chat/completions.py:322\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    199\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/groq/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/groq/_base_client.py:958\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    956\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/groq/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/groq/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m.\u001b[39murl, timeout)\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m-> 1093\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1096\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1097\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1101\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "  \"input\":\"1706.03762\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
